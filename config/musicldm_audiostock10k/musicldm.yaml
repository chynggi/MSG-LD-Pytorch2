project_name: "controllable-text-to-music-audiostock10k"
log_directory: "/home/kechen/research/CTTM/Controllable_TTM/logs/musicldm"
test_mode: True


id: 
  version: "v1"
  name: "2023_05_05_musicldm_audiostock10k_Rilke_infer_finegrained"

step:
  validation_every_n_steps: 50000
  save_checkpoint_every_n_steps: 25000
  save_top_k: 3

augmentation:
  mixup: 0.0
  return_all_wav: False
  balanced_sampling: False

path:
  dataset_type: "audiostock"
  train_data: "/graft1/datasets/kechen/audiostock-10k-16khz/train"
  test_data: "/graft1/datasets/kechen/audiostock-10k-16khz/poem-audio"
  label_data: "/graft1/datasets/kechen/audiostock-10k-16khz/label"
  tempo_data: "/graft1/datasets/kechen/audiostock-10k-16khz/tempo/train"
  tempo_map: "/home/kechen/research/CTTM/Controllable_TTM/audiostock_tempomap_all.npy"
  
preprocessing:
  label:
    norm: True
    top_k: 527
    quantization: False
    threshold: 0.01
    label_use_original_ground_truth: False
  audio:
    sampling_rate: 16000
    max_wav_value: 32768.0
  stft:
    filter_length: 1024
    hop_length: 160
    win_length: 1024
  mel:
    n_mel_channels: 64 # TODO might need to change # 64 or 128
    mel_fmin: 0
    mel_fmax: 8000 # please set to 8000 for HiFi-GAN vocoder, set to null for MelGAN vocoder
    freqm: 0
    timem: 0
    blur: False
    # mean: -4.63
    # std: 2.74
    target_length: 1024

model:
  target: latent_diffusion.models.musicldm.MusicLDM
  num_workers: 8
  params:
    base_learning_rate: 3.0e-05
    batchsize: 24
    linear_start: 0.0015
    linear_end: 0.0195
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: fbank
    cond_stage_key: waveform # waveform | text
    latent_t_size: 256 # TODO might need to change # (256, 16) or (128,16)
    latent_f_size: 16 
    channels: 8 # TODO might need to change # 8 or 16
    cond_stage_trainable: true
    latent_mixup: 0.0
    conditioning_key: film
    monitor: val/loss_simple_ema
    scale_by_std: true
    ckpt_path: '/home/kechen/research/CTTM/Controllable_TTM/logs/musicldm/controllable-text-to-music-audiostock10k/2023_04_04_musicldm_audiostock10k_3e-05_v1_1680810638/checkpoints/checkpoint-fad-0.00-global_step=449999.ckpt'
    # "/home/kechen/research/CTTM/Controllable_TTM/logs/musicldm/controllable-text-to-music-audiostock10k/2023_05_05_musicldm_audiostock10k_audio_mixup_text_finetune_3e-05_v1_1683926254/checkpoints/last.ckpt"
    # "/home/kechen/research/CTTM/Controllable_TTM/logs/musicldm/controllable-text-to-music-audiostock10k/2023_04_04_musicldm_audiostock10k_3e-05_v1_1680810638/checkpoints/checkpoint-fad-0.00-global_step=449999.ckpt"
    unet_config:
      target: latent_diffusion.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 64 # Ignore this parameter
        extra_film_condition_dim: 512
        extra_film_use_concat: true
        in_channels: 8 # TODO might need to change # 8 or 16
        out_channels: 8 # TODO might need to change # 8 or 16
        model_channels: 128 # TODO might need to change
        no_condition: false
        attention_resolutions:
        - 8
        - 4
        - 2
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 3
        - 5
        num_head_channels: 32
        use_spatial_transformer: true
    first_stage_config:
      base_learning_rate: 4.5e-05
      target: latent_encoder.autoencoder.AutoencoderKL
      params:
        reload_from_ckpt: '/home/kechen/research/CTTM/Controllable_TTM/logs/vae/CTTM-VAE-2023-03-01/2023_03_01_autoencoder_mel_8_128_4.5e-06_v1_1678179907/checkpoints/checkpoint-train_step=70000-aeloss_val=7395.453.ckpt'
        # "/home/kechen/research/CTTM/Controllable_TTM/logs/vae-mixup/CTTM-VAE-MIXUP-2023-05-04/2023_05_04_autoencoder_mel_mixup_16_128_4.5e-06_v1_1683453017/checkpoints/checkpoint-train_step=135000-aeloss_val=27148.100.ckpt"
        batchsize: 4
        monitor: val/rec_loss
        image_key: fbank
        subband: 1
        embed_dim: 8 # TODO might need to change # 8 or 16
        time_shuffle: 1
        mel_num: 64 # TODO might need to change 64 or 128
        lossconfig:
          target: latent_diffusion.modules.losses.LPIPSWithDiscriminator
          params:
            disc_start: 50001
            kl_weight: 1.0
            disc_weight: 0.5
            disc_in_channels: 1
        ddconfig:
          double_z: true
          z_channels: 8 # TODO might need to change # 8 or 16
          resolution: 256
          downsample_time: false
          in_channels: 1
          out_ch: 1
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          # - 8 # TODO might need to change
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0

    cond_stage_config:
      target: latent_diffusion.modules.encoders.modules.CLAPAudioEmbeddingClassifierFreev2
      params:
        pretrained_path: /home/kechen/research/CTTM/ckpt/music_audioset_epoch_15_esc_90.14.pt
        sampling_rate: 16000
        embed_mode: audio # or text audio
        unconditional_prob: 0.1

    evaluation_params:
      unconditional_guidance_scale: 2.0
      ddim_sampling_steps: 200
      n_candidates_per_samples: 5