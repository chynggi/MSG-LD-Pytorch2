project_name: "controllable-music-generation-soundcloud"
log_directory: "/home/kechen/research/CTTM/Controllable_TTM/logs/musicldm"
test_mode: True

id: 
  version: "v1"
  name: "2023_04_30_musicldm_soundcloud-16k"

step:
  validation_every_n_steps: 200000
  save_checkpoint_every_n_steps: 50000
  save_top_k: 3

augmentation:
  mixup: 0.0
  balanced_sampling: False

path:
  dataset_type: "audiostock"
  train_data: "/trunk/datasets/kechen/soundcloud-16k/train"
  test_data: "/trunk/datasets/kechen/soundcloud-16k/test"
  label_data: null
  
preprocessing:
  label:
    norm: True
    top_k: 527
    quantization: False
    threshold: 0.01
    label_use_original_ground_truth: False
  audio:
    sampling_rate: 16000
    max_wav_value: 32768.0
  stft:
    filter_length: 1024
    hop_length: 160
    win_length: 1024
  mel:
    n_mel_channels: 128
    mel_fmin: 0
    mel_fmax: 8000 # please set to 8000 for HiFi-GAN vocoder, set to null for MelGAN vocoder
    freqm: 0
    timem: 0
    blur: False
    # mean: -4.63
    # std: 2.74
    target_length: 1024

model:
  # reload_from_ckpt: "/mnt/fast/nobackup/scratch4weeks/hl01486/exps/audio_generation/stablediffusion/LDM/audioverse/2023_01_23_full_F4_S_spatial_full_v1/checkpoints/last.ckpt"
  target: latent_diffusion.models.musicldm.MusicLDM
  num_workers: 8
  params:
    base_learning_rate: 3.0e-05
    batchsize: 64
    linear_start: 0.0015
    linear_end: 0.0195
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: fbank
    cond_stage_key: waveform # or text
    latent_t_size: 128 # TODO might need to change
    latent_f_size: 16
    channels: 16 # TODO might need to change
    cond_stage_trainable: false
    conditioning_key: film
    monitor: val/loss_simple_ema
    scale_by_std: true
    ckpt_path: "/home/kechen/research/CTTM/Controllable_TTM/logs/musicldm/controllable-music-generation-soundcloud/2023_04_30_musicldm_soundcloud-16k_3e-05_v1_1682927254/checkpoints/checkpoint-fad-0.00-global_step=149999.ckpt"
    unet_config:
      target: latent_diffusion.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 64 # Ignore this parameter
        extra_film_condition_dim: null
        extra_film_use_concat: false
        in_channels: 16 # TODO might need to change
        out_channels: 16 # TODO might need to change
        model_channels: 128 # TODO might need to change
        no_condition: true
        attention_resolutions:
        - 8
        - 4
        - 2
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 3
        - 5
        num_head_channels: 32
        use_spatial_transformer: true
    first_stage_config:
      base_learning_rate: 4.5e-05
      target: latent_encoder.autoencoder.AutoencoderKL
      params:
        reload_from_ckpt: "/home/kechen/research/CTTM/Controllable_TTM/logs/vae_sd/CTTM-VAE-2023-04-01/2023_04_01_autoencoder_mel_sd_16_128_4.5e-06_v1_1682410592/checkpoints/checkpoint-train_step=210000-aeloss_val=26366.139.ckpt"
        batchsize: 4
        monitor: val/rec_loss
        image_key: fbank
        subband: 1
        embed_dim: 16
        time_shuffle: 1
        mel_num: 128
        lossconfig:
          target: latent_diffusion.modules.losses.LPIPSWithDiscriminator
          params:
            disc_start: 50001
            kl_weight: 1.0
            disc_weight: 0.5
            disc_in_channels: 1
        ddconfig:
          double_z: true
          z_channels: 16
          resolution: 256
          downsample_time: false
          in_channels: 1
          out_ch: 1
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 8
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0

    cond_stage_config: __is_unconditional__
      # target: latent_diffusion.modules.encoders.modules.CLAPAudioEmbeddingClassifierFreev2
      # params:
      #   pretrained_path: /home/kechen/research/CTTM/ckpt/music_audioset_epoch_15_esc_90.14.pt
      #   sampling_rate: 16000
      #   embed_mode: audio # or text
      #   unconditional_prob: 0.1

    evaluation_params:
      unconditional_guidance_scale: 1.0
      ddim_sampling_steps: 200
      n_candidates_per_samples: 1